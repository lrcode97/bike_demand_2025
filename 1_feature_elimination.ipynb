{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Set style\n",
    "plt.style.use('ggplot')\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BikeDemandDataProcessor:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def load_data(self, filename):\n",
    "        full_path = f\"{self.path}/{filename}\"\n",
    "        print(f\"Loading data from {full_path}\")\n",
    "        try:\n",
    "            return pd.read_csv(full_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filename} not found in path {self.path}.\")\n",
    "            return None\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        df = df.copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['dteday'] + ' ' + df['hr'].astype(str) + ':00:00', format='%d/%m/%Y %H:%M:%S')\n",
    "        df.rename(columns={'hr': 'hour', 'yr' : 'year', 'mnth' : 'month', 'cnt' : 'count'}, inplace=True)\n",
    "        df.drop(['dteday', 'instant'], axis=1, inplace=True)\n",
    "\n",
    "        # Creating time-based features\n",
    "        df['payday'] = df['timestamp'].dt.is_month_end.astype(int)\n",
    "        df['year'] = df['timestamp'].dt.year\n",
    "        df['day'] = df['timestamp'].dt.day_of_year\n",
    "        df['day_of_week'] = df['timestamp'].dt.day_of_week\n",
    "        df['day_of_month'] = df['timestamp'].dt.day\n",
    "        df['month'] = df['timestamp'].dt.month\n",
    "        df['week'] = df['timestamp'].dt.isocalendar().week\n",
    "        df['year_sin'] = np.sin(2 * np.pi * df['year'])\n",
    "        df['year_cos'] = np.cos(2 * np.pi * df['year'])\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12) \n",
    "        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "        df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)  \n",
    "        df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)\n",
    "        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "        df['working_day'] = df['day_of_week'].apply(lambda x: 1 if x < 5 else 0)\n",
    "        df['weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "        df['moonphase'] = df['timestamp'].apply(lambda x: (x.day + x.month * 29.53) % 29.53)\n",
    "        df['quarter'] = df['timestamp'].dt.quarter\n",
    "        df['christmas'] = df['timestamp'].apply(lambda x: 1 if x.month == 12 and x.day >= 20 else 0)\n",
    "        df['day_of_year'] = df['timestamp'].dt.dayofyear\n",
    "\n",
    "        # Creating rush hour feature\n",
    "        df['rush_hour'] = df.apply(lambda x: 1 if ((x['hour'] >= 4 and x['hour'] <= 10) or (x['hour'] >= 15 and x['hour'] <= 21)) and x['working_day'] == 1 else 0, axis=1)\n",
    "\n",
    "        # Convert object columns to category\n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "        return df.drop_duplicates()\n",
    "    \n",
    "    def feature_engineering(self, train_df, val_df):\n",
    "        train_df = train_df.copy()\n",
    "        val_df = val_df.copy()\n",
    "\n",
    "        # Avoid division by zero\n",
    "        casual_sum = train_df['casual'].sum()\n",
    "        if casual_sum == 0:\n",
    "            casual_sum = 1  # Prevent division by zero\n",
    "\n",
    "        total_ratio_of_registered_uses = train_df['registered'].sum() / casual_sum\n",
    "\n",
    "        # Average ratios for different time-based groupings\n",
    "        average_hour_ratio = train_df.groupby('hour').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "        average_day_ratio = train_df.groupby('day_of_week').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "        average_week_ratio = train_df.groupby('week').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "        average_month_ratio = train_df.groupby('month').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "        average_season_ratio = train_df.groupby('season').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "        average_weekend_ratio = train_df.groupby('weekend').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "        average_working_day_ratio = train_df.groupby('working_day').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
    "\n",
    "        # Applying ratios to both train and validation sets\n",
    "        train_df['total_registered_ratio'] = total_ratio_of_registered_uses\n",
    "        val_df['total_registered_ratio'] = total_ratio_of_registered_uses\n",
    "\n",
    "        train_df['hour_ratio'] = train_df['hour'].map(average_hour_ratio)\n",
    "        val_df['hour_ratio'] = val_df['hour'].map(average_hour_ratio)\n",
    "\n",
    "        train_df['day_ratio'] = train_df['day_of_week'].map(average_day_ratio)\n",
    "        val_df['day_ratio'] = val_df['day_of_week'].map(average_day_ratio)\n",
    "\n",
    "        # Now use these ratios wherever needed for working day and weekend conditions\n",
    "        train_df['working_day_or_weekend_ratio'] = train_df['working_day'].map(average_working_day_ratio).where(train_df['working_day'] == 1, \n",
    "                                                                                                                        train_df['weekend'].map(average_weekend_ratio))\n",
    "        val_df['working_day_or_weekend_ratio'] = val_df['working_day'].map(average_working_day_ratio).where(val_df['working_day'] == 1, \n",
    "                                                                                                                    val_df['weekend'].map(average_weekend_ratio))\n",
    "\n",
    "        train_df['week_ratio'] = train_df['week'].map(average_week_ratio)\n",
    "        val_df['week_ratio'] = val_df['week'].map(average_week_ratio)\n",
    "\n",
    "        train_df['month_ratio'] = train_df['month'].map(average_month_ratio)\n",
    "        val_df['month_ratio'] = val_df['month'].map(average_month_ratio)\n",
    "\n",
    "        train_df['season_ratio'] = train_df['season'].map(average_season_ratio)\n",
    "        val_df['season_ratio'] = val_df['season'].map(average_season_ratio)\n",
    "\n",
    "        # Dropping original target columns\n",
    "        train_df.drop(['casual', 'registered'], axis=1, inplace=True)\n",
    "        val_df.drop(['casual', 'registered'], axis=1, inplace=True)\n",
    "\n",
    "        # Aggregate counts to daily level\n",
    "        daily_train_df = train_df.groupby(['year', 'month', 'day', 'day_of_year'])[['count']].sum().reset_index()\n",
    "\n",
    "\n",
    "        # Calculate rolling mean and standard deviation (2-week window)\n",
    "        rolling_mean = daily_train_df['count'].rolling(window=14, center=True).mean()\n",
    "        rolling_std = daily_train_df['count'].rolling(window=14, center=True).std()\n",
    "\n",
    "        # Identify 3-sigma outliers\n",
    "        daily_train_df['sigma_3_outlier'] = (daily_train_df['count'] > rolling_mean + 3 * rolling_std) | \\\n",
    "                                            (daily_train_df['count'] < rolling_mean - 3 * rolling_std)\n",
    "\n",
    "        # Find max outlier flag per day_of_year\n",
    "        day_of_year_outlier = daily_train_df.groupby('day_of_year', as_index=False)['sigma_3_outlier'].max()\n",
    "\n",
    "        # Merge back into train_df and val_df\n",
    "        train_df = train_df.merge(day_of_year_outlier, on='day_of_year', how='left')\n",
    "        val_df = val_df.merge(day_of_year_outlier, on='day_of_year', how='left')\n",
    "\n",
    "        # Fill NaN values (if no outlier was detected for that day, assume False)\n",
    "        train_df['sigma_3_outlier'].fillna(False, inplace=True)\n",
    "        val_df['sigma_3_outlier'].fillna(False, inplace=True)\n",
    "\n",
    "\n",
    "        return train_df.drop_duplicates(), val_df.drop_duplicates()\n",
    "\n",
    "        \n",
    "\n",
    "        return train_df.drop_duplicates(), val_df.drop_duplicates()\n",
    "    \n",
    "    def split_and_engineer_data(self, df):\n",
    "        sorted_df = df.sort_values('timestamp').copy()\n",
    "        sorted_df.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "        train_df, val_df = train_test_split(sorted_df, test_size=0.2, shuffle=False)\n",
    "\n",
    "        train_df, val_df = self.feature_engineering(train_df, val_df)\n",
    "\n",
    "        return train_df, val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inverse_boxcox(y_transformed, lambda_value):\n",
    "    return (y_transformed * lambda_value + 1) ** (1 / lambda_value) - 1 if lambda_value != 0 else np.exp(y_transformed) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/lawrence/Documents/PYTHON/saga_tech_test_2025/hour.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "parent_path = Path().resolve()\n",
    "processor = BikeDemandDataProcessor(parent_path)\n",
    "hour_raw_df = processor.load_data(\"hour.csv\")\n",
    "hour_processed_df = processor.preprocess(hour_raw_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for missing data\n",
    "null_counts = hour_processed_df.isnull().sum()\n",
    "print(null_counts[null_counts > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:64: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_hour_ratio = train_df.groupby('hour').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_day_ratio = train_df.groupby('day_of_week').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_week_ratio = train_df.groupby('week').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:67: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_month_ratio = train_df.groupby('month').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:68: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_season_ratio = train_df.groupby('season').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_weekend_ratio = train_df.groupby('weekend').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:70: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_working_day_ratio = train_df.groupby('working_day').apply(lambda x: x['registered'].sum() / (x['casual'].sum() or 1))\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:121: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['sigma_3_outlier'].fillna(False, inplace=True)\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:122: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  val_df['sigma_3_outlier'].fillna(False, inplace=True)\n",
      "/var/folders/_1/31ptxk6d3nn4qzvtp4ln67dw0000gn/T/ipykernel_1768/1637802544.py:122: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  val_df['sigma_3_outlier'].fillna(False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_df, val_df = processor.split_and_engineer_data(hour_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday',\n",
       "       'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'count', 'payday',\n",
       "       'day', 'day_of_week', 'day_of_month', 'week', 'year_sin', 'year_cos',\n",
       "       'month_sin', 'month_cos', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos',\n",
       "       'working_day', 'weekend', 'moonphase', 'quarter', 'christmas',\n",
       "       'day_of_year', 'rush_hour', 'total_registered_ratio', 'hour_ratio',\n",
       "       'day_ratio', 'working_day_or_weekend_ratio', 'week_ratio',\n",
       "       'month_ratio', 'season_ratio', 'sigma_3_outlier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# Your feature list - corrected to match actual column names\n",
    "features_in_importance_order = ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', \n",
    "                                'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', \n",
    "                                'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', \n",
    "                                'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', \n",
    "                                'moonphase', 'day_cos', 'month']\n",
    "\n",
    "# Define features and target\n",
    "target = 'count'\n",
    "\n",
    "numeric_columns = ['temp', 'atemp', 'hum', 'windspeed', 'year_sin', 'month_cos', \n",
    "                   'day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'moonphase', 'hour_ratio', \n",
    "                   'day_ratio', 'week_ratio', 'working_day_or_weekend_ratio']\n",
    "\n",
    "categorical_label_encode_columns = ['season', 'year', 'month', 'hour', 'day_of_week', 'weathersit','day', 'week']\n",
    "\n",
    "categorical_one_hot_columns = ['holiday', 'working_day', 'weekend', 'rush_hour']\n",
    "\n",
    "\n",
    "# Combine features into one list\n",
    "features = numeric_columns + categorical_label_encode_columns + categorical_one_hot_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>working_day</th>\n",
       "      <th>weekend</th>\n",
       "      <th>rush_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.295466e-12</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.295466e-12</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.295466e-12</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.295466e-12</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.295466e-12</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp   atemp   hum  windspeed      year_sin  month_cos   day_sin  day_cos  \\\n",
       "0  0.24  0.2879  0.81        0.0 -1.295466e-12   0.866025  0.201299  0.97953   \n",
       "1  0.22  0.2727  0.80        0.0 -1.295466e-12   0.866025  0.201299  0.97953   \n",
       "2  0.22  0.2727  0.80        0.0 -1.295466e-12   0.866025  0.201299  0.97953   \n",
       "3  0.24  0.2879  0.75        0.0 -1.295466e-12   0.866025  0.201299  0.97953   \n",
       "4  0.24  0.2879  0.75        0.0 -1.295466e-12   0.866025  0.201299  0.97953   \n",
       "\n",
       "   hour_sin  hour_cos  ...  month  hour  day_of_week  weathersit  day  week  \\\n",
       "0  0.000000  1.000000  ...      1     0            5           1    1    52   \n",
       "1  0.258819  0.965926  ...      1     1            5           1    1    52   \n",
       "2  0.500000  0.866025  ...      1     2            5           1    1    52   \n",
       "3  0.707107  0.707107  ...      1     3            5           1    1    52   \n",
       "4  0.866025  0.500000  ...      1     4            5           1    1    52   \n",
       "\n",
       "   holiday  working_day  weekend  rush_hour  \n",
       "0        0            0        1          0  \n",
       "1        0            0        1          0  \n",
       "2        0            0        1          0  \n",
       "3        0            0        1          0  \n",
       "4        0            0        1          0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>holiday</th>\n",
       "      <th>working_day</th>\n",
       "      <th>weekend</th>\n",
       "      <th>rush_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>-6.349064e-13</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>-6.349064e-13</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-6.349064e-13</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-6.349064e-13</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>-6.349064e-13</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.571268</td>\n",
       "      <td>0.820763</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp   atemp   hum  windspeed      year_sin  month_cos   day_sin   day_cos  \\\n",
       "0  0.80  0.7576  0.55     0.1343 -6.349064e-13       -0.5  0.571268  0.820763   \n",
       "1  0.80  0.7424  0.52     0.1940 -6.349064e-13       -0.5  0.571268  0.820763   \n",
       "2  0.82  0.7576  0.46     0.0000 -6.349064e-13       -0.5  0.571268  0.820763   \n",
       "3  0.80  0.7424  0.52     0.0000 -6.349064e-13       -0.5  0.571268  0.820763   \n",
       "4  0.76  0.7273  0.66     0.2836 -6.349064e-13       -0.5  0.571268  0.820763   \n",
       "\n",
       "       hour_sin  hour_cos  ...  month  hour  day_of_week  weathersit  day  \\\n",
       "0  1.224647e-16 -1.000000  ...      8    12            1           2  220   \n",
       "1 -2.588190e-01 -0.965926  ...      8    13            1           2  220   \n",
       "2 -5.000000e-01 -0.866025  ...      8    14            1           2  220   \n",
       "3 -7.071068e-01 -0.707107  ...      8    15            1           1  220   \n",
       "4 -8.660254e-01 -0.500000  ...      8    16            1           3  220   \n",
       "\n",
       "   week  holiday  working_day  weekend  rush_hour  \n",
       "0    32        0            1        0          0  \n",
       "1    32        0            1        0          0  \n",
       "2    32        0            1        0          0  \n",
       "3    32        0            1        0          1  \n",
       "4    32        0            1        0          1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 28 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', 'moonphase', 'day_cos', 'month']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:43:21,076 - INFO - Features: 28 | RMSE: 61.0845 | RMSLE: 0.3811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', 'moonphase', 'day_cos']\n",
      "Using 27 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', 'moonphase', 'day_cos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:43:28,461 - INFO - Features: 27 | RMSE: 60.8900 | RMSLE: 0.3831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', 'moonphase']\n",
      "Using 26 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', 'moonphase']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:43:34,750 - INFO - Features: 26 | RMSE: 61.2456 | RMSLE: 0.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin']\n",
      "Using 25 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:43:41,711 - INFO - Features: 25 | RMSE: 61.7349 | RMSLE: 0.3710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday']\n",
      "Using 24 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:43:48,877 - INFO - Features: 24 | RMSE: 62.7223 | RMSLE: 0.3811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio']\n",
      "Using 23 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:43:55,457 - INFO - Features: 23 | RMSE: 66.8783 | RMSLE: 0.4050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week']\n",
      "Using 22 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:01,259 - INFO - Features: 22 | RMSE: 66.8783 | RMSLE: 0.4050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed']\n",
      "Using 21 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:06,885 - INFO - Features: 21 | RMSE: 68.7678 | RMSLE: 0.4171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend']\n",
      "Using 20 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:12,188 - INFO - Features: 20 | RMSE: 65.8031 | RMSLE: 0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos']\n",
      "Using 19 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:17,603 - INFO - Features: 19 | RMSE: 65.8031 | RMSLE: 0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio']\n",
      "Using 18 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:22,687 - INFO - Features: 18 | RMSE: 64.3895 | RMSLE: 0.3987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season']\n",
      "Using 17 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:27,627 - INFO - Features: 17 | RMSE: 68.9547 | RMSLE: 0.4211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio']\n",
      "Using 16 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:32,527 - INFO - Features: 16 | RMSE: 68.7064 | RMSLE: 0.4088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year']\n",
      "Using 15 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:37,554 - INFO - Features: 15 | RMSE: 67.9343 | RMSLE: 0.4154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum']\n",
      "Using 14 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:42,393 - INFO - Features: 14 | RMSE: 67.9343 | RMSLE: 0.4154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day']\n",
      "Using 13 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:48,140 - INFO - Features: 13 | RMSE: 74.2683 | RMSLE: 0.4295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week']\n",
      "Using 12 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:53,774 - INFO - Features: 12 | RMSE: 89.7892 | RMSLE: 0.4938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit']\n",
      "Using 11 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:44:59,513 - INFO - Features: 11 | RMSE: 93.4754 | RMSLE: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day']\n",
      "Using 10 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:06,514 - INFO - Features: 10 | RMSE: 101.0564 | RMSLE: 0.5464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos']\n",
      "Using 9 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:13,132 - INFO - Features: 9 | RMSE: 113.4927 | RMSLE: 0.6467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour']\n",
      "Using 8 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:18,185 - INFO - Features: 8 | RMSE: 113.6224 | RMSLE: 0.6444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin']\n",
      "Using 7 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:23,188 - INFO - Features: 7 | RMSE: 140.6332 | RMSLE: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year']\n",
      "Using 6 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:28,079 - INFO - Features: 6 | RMSE: 140.6332 | RMSLE: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin']\n",
      "Using 5 features: ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:33,298 - INFO - Features: 5 | RMSE: 163.4913 | RMSLE: 0.7683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio', 'temp']\n",
      "Using 4 features: ['hour', 'atemp', 'hour_ratio', 'temp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:39,086 - INFO - Features: 4 | RMSE: 163.2931 | RMSLE: 0.7652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'hour_ratio']\n",
      "Using 3 features: ['hour', 'atemp', 'hour_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:45,869 - INFO - Features: 3 | RMSE: 162.0745 | RMSLE: 0.7334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp']\n",
      "Using 2 features: ['hour', 'atemp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:51,932 - INFO - Features: 2 | RMSE: 162.0697 | RMSLE: 0.7326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour']\n",
      "Using 1 features: ['hour']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:45:56,310 - INFO - Features: 1 | RMSE: 183.2609 | RMSLE: 0.7745\n",
      "2025-03-08 19:45:56,311 - INFO - Best Features (27): ['hour', 'atemp', 'hour_ratio', 'temp', 'hour_sin', 'year', 'year_sin', 'rush_hour', 'hour_cos', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'day_sin', 'moonphase', 'day_cos'] | Best RMSE: 60.8900 | Best RMSLE: 0.3831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "categorical_onehot_transformer = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Label encoding for other categorical columns\n",
    "categorical_label_transformer = Pipeline([\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Preprocessor will be defined inside the loop for each feature subset\n",
    "\n",
    "# Log1p transformation\n",
    "y_train, lambda_value = boxcox(train_df['count'] + 1)\n",
    "\n",
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'num_leaves': 35,  \n",
    "    'learning_rate': 0.1,  \n",
    "    'n_estimators': 5000, \n",
    "}\n",
    "\n",
    "# Track best metrics\n",
    "best_rmse = float(\"inf\")\n",
    "best_rmsle = float(\"inf\")\n",
    "best_features = None\n",
    "\n",
    "# Create a list to store all results\n",
    "all_results = []\n",
    "\n",
    "# First run with all features\n",
    "n_features = len(features_in_importance_order)\n",
    "selected_features = features_in_importance_order.copy()\n",
    "\n",
    "# Evaluate performance by progressively removing features from the end\n",
    "for i in range(0, len(features_in_importance_order)):\n",
    "    if i > 0:\n",
    "        # Remove the last feature for each iteration after the first\n",
    "        selected_features = features_in_importance_order[:-i]\n",
    "        print('New selected features:', selected_features)\n",
    "    \n",
    "    # Check if all selected features exist in the dataset\n",
    "    valid_features = [f for f in selected_features if f in train_df.columns]\n",
    "    if len(valid_features) != len(selected_features):\n",
    "        logging.warning(f\"Some features not found in dataset: {set(selected_features) - set(valid_features)}\")\n",
    "        selected_features = valid_features\n",
    "    \n",
    "    # Get training data with selected features\n",
    "    new_X_train = train_df[selected_features].copy()\n",
    "    print(f\"Using {len(selected_features)} features: {selected_features}\")\n",
    "\n",
    "     # Process validation data and make predictions\n",
    "    # Create filtered feature lists based on the current selected features\n",
    "    current_numeric_columns = [col for col in numeric_columns if col in selected_features]\n",
    "    current_categorical_one_hot_columns = [col for col in categorical_one_hot_columns if col in selected_features]\n",
    "    current_categorical_label_encode_columns = [col for col in categorical_label_encode_columns if col in selected_features]\n",
    "\n",
    "    # print(f\"Current numeric columns: {current_numeric_columns}\")\n",
    "    # print(f\"Current one-hot columns: {current_categorical_one_hot_columns}\")\n",
    "    # print(f\"Current label encode columns: {current_categorical_label_encode_columns}\")   \n",
    "\n",
    "    # Create a new preprocessor with current features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, current_numeric_columns),\n",
    "            (\"cat_onehot\", categorical_onehot_transformer, current_categorical_one_hot_columns),\n",
    "            (\"cat_label\", categorical_label_transformer, current_categorical_label_encode_columns)\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the preprocessor\n",
    "    X_train_processed = preprocessor.fit_transform(new_X_train)\n",
    "    \n",
    "    # Create and fit LightGBM model\n",
    "    model = lgb.LGBMRegressor(**params, verbosity=-1)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    \n",
    "    # Fit the preprocessor\n",
    "    X_train_processed = preprocessor.fit_transform(new_X_train)\n",
    "\n",
    "    # Process validation data and make predictions\n",
    "    X_val = val_df[selected_features]\n",
    "    y_val = val_df[target]\n",
    "    X_val_processed = preprocessor.transform(X_val)\n",
    "    y_pred = model.predict(X_val_processed)\n",
    "    \n",
    "    # Apply inverse transformation\n",
    "    y_pred_inv = inverse_boxcox(y_pred, lambda_value)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_val, y_pred_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmsle = np.sqrt(mean_squared_error(np.log1p(y_val), np.log1p(y_pred_inv)))\n",
    "    \n",
    "    # Store results\n",
    "    all_results.append({\n",
    "        'n_features': len(selected_features),\n",
    "        'features': selected_features.copy(),\n",
    "        'rmse': rmse,\n",
    "        'rmsle': rmsle\n",
    "    })\n",
    "    \n",
    "    # Log the metrics\n",
    "    logging.info(f\"Features: {len(selected_features)} | RMSE: {rmse:.4f} | RMSLE: {rmsle:.4f}\")\n",
    "    \n",
    "    # Track the best performing feature subset\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_rmsle = rmsle\n",
    "        best_features = selected_features.copy()\n",
    "\n",
    "# Sort results by RMSE to find optimal feature count\n",
    "all_results.sort(key=lambda x: x['rmse'])\n",
    "best_result = all_results[0]\n",
    "\n",
    "logging.info(f\"Best Features ({best_result['n_features']}): {best_result['features']} | Best RMSE: {best_result['rmse']:.4f} | Best RMSLE: {best_result['rmsle']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 21 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'moonphase']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:07,916 - INFO - Features: 21 | RMSE: 63.1772 | RMSLE: 0.3879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday']\n",
      "Using 20 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:16,238 - INFO - Features: 20 | RMSE: 63.2579 | RMSLE: 0.3824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio']\n",
      "Using 19 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:25,003 - INFO - Features: 19 | RMSE: 67.3725 | RMSLE: 0.4107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week']\n",
      "Using 18 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:32,467 - INFO - Features: 18 | RMSE: 67.3725 | RMSLE: 0.4107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed']\n",
      "Using 17 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:40,074 - INFO - Features: 17 | RMSE: 70.3370 | RMSLE: 0.4178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend']\n",
      "Using 16 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:47,339 - INFO - Features: 16 | RMSE: 68.8141 | RMSLE: 0.4186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos']\n",
      "Using 15 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:53:53,996 - INFO - Features: 15 | RMSE: 68.8141 | RMSLE: 0.4186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio']\n",
      "Using 14 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:00,274 - INFO - Features: 14 | RMSE: 67.7643 | RMSLE: 0.4090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season']\n",
      "Using 13 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:07,164 - INFO - Features: 13 | RMSE: 67.7123 | RMSLE: 0.4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio']\n",
      "Using 12 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:15,739 - INFO - Features: 12 | RMSE: 66.6147 | RMSLE: 0.4222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year']\n",
      "Using 11 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:22,106 - INFO - Features: 11 | RMSE: 67.9929 | RMSLE: 0.4258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum']\n",
      "Using 10 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:30,176 - INFO - Features: 10 | RMSE: 67.9929 | RMSLE: 0.4258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day']\n",
      "Using 9 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:42,977 - INFO - Features: 9 | RMSE: 75.8844 | RMSLE: 0.4466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week']\n",
      "Using 8 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:51,567 - INFO - Features: 8 | RMSE: 88.2216 | RMSLE: 0.5033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit']\n",
      "Using 7 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:54:56,955 - INFO - Features: 7 | RMSE: 93.1288 | RMSLE: 0.5121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day']\n",
      "Using 6 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:55:02,341 - INFO - Features: 6 | RMSE: 100.2434 | RMSLE: 0.5424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year', 'rush_hour']\n",
      "Using 5 features: ['hour', 'atemp', 'temp', 'year', 'rush_hour']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:55:08,804 - INFO - Features: 5 | RMSE: 113.6144 | RMSLE: 0.6490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp', 'year']\n",
      "Using 4 features: ['hour', 'atemp', 'temp', 'year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:55:16,277 - INFO - Features: 4 | RMSE: 140.1900 | RMSLE: 0.7318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp', 'temp']\n",
      "Using 3 features: ['hour', 'atemp', 'temp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:55:21,923 - INFO - Features: 3 | RMSE: 163.5142 | RMSLE: 0.7660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour', 'atemp']\n",
      "Using 2 features: ['hour', 'atemp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:55:30,451 - INFO - Features: 2 | RMSE: 162.0697 | RMSLE: 0.7326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New selected features: ['hour']\n",
      "Using 1 features: ['hour']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025-03-08 19:55:37,587 - INFO - Features: 1 | RMSE: 183.2609 | RMSLE: 0.7745\n",
      "2025-03-08 19:55:37,588 - INFO - Best Features (21): ['hour', 'atemp', 'temp', 'year', 'rush_hour', 'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', 'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', 'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', 'moonphase'] | Best RMSE: 63.1772 | Best RMSLE: 0.3879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# Your feature list - corrected to match actual column names\n",
    "features_in_importance_order = ['hour', 'atemp' , 'temp', 'year', 'rush_hour', \n",
    "                                'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', \n",
    "                                'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', \n",
    "                                'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', \n",
    "                                'moonphase']\n",
    "\n",
    "# Define features and target\n",
    "target = 'count'\n",
    "\n",
    "numeric_columns = ['temp', 'atemp', 'hum', 'windspeed', 'month_cos', \n",
    "                    'moonphase', 'hour_ratio', \n",
    "                   'day_ratio', 'week_ratio', 'working_day_or_weekend_ratio']\n",
    "\n",
    "categorical_label_encode_columns = ['season', 'year', 'month', 'hour', 'day_of_week', 'weathersit','day', 'week']\n",
    "\n",
    "categorical_one_hot_columns = ['holiday', 'working_day', 'weekend', 'rush_hour']\n",
    "\n",
    "\n",
    "# Combine features into one list\n",
    "features = numeric_columns + categorical_label_encode_columns + categorical_one_hot_columns\n",
    "\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "categorical_onehot_transformer = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Label encoding for other categorical columns\n",
    "categorical_label_transformer = Pipeline([\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Preprocessor will be defined inside the loop for each feature subset\n",
    "\n",
    "# Log1p transformation\n",
    "y_train, lambda_value = boxcox(train_df['count'] + 1)\n",
    "\n",
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'num_leaves': 35,  \n",
    "    'learning_rate': 0.1,  \n",
    "    'n_estimators': 5000, \n",
    "}\n",
    "\n",
    "# Track best metrics\n",
    "best_rmse = float(\"inf\")\n",
    "best_rmsle = float(\"inf\")\n",
    "best_features = None\n",
    "\n",
    "# Create a list to store all results\n",
    "all_results = []\n",
    "\n",
    "# First run with all features\n",
    "n_features = len(features_in_importance_order)\n",
    "selected_features = features_in_importance_order.copy()\n",
    "\n",
    "# Evaluate performance by progressively removing features from the end\n",
    "for i in range(0, len(features_in_importance_order)):\n",
    "    if i > 0:\n",
    "        # Remove the last feature for each iteration after the first\n",
    "        selected_features = features_in_importance_order[:-i]\n",
    "        print('New selected features:', selected_features)\n",
    "    \n",
    "    # Check if all selected features exist in the dataset\n",
    "    valid_features = [f for f in selected_features if f in train_df.columns]\n",
    "    if len(valid_features) != len(selected_features):\n",
    "        logging.warning(f\"Some features not found in dataset: {set(selected_features) - set(valid_features)}\")\n",
    "        selected_features = valid_features\n",
    "    \n",
    "    # Get training data with selected features\n",
    "    new_X_train = train_df[selected_features].copy()\n",
    "    print(f\"Using {len(selected_features)} features: {selected_features}\")\n",
    "\n",
    "     # Process validation data and make predictions\n",
    "    # Create filtered feature lists based on the current selected features\n",
    "    current_numeric_columns = [col for col in numeric_columns if col in selected_features]\n",
    "    current_categorical_one_hot_columns = [col for col in categorical_one_hot_columns if col in selected_features]\n",
    "    current_categorical_label_encode_columns = [col for col in categorical_label_encode_columns if col in selected_features]\n",
    "\n",
    "    # print(f\"Current numeric columns: {current_numeric_columns}\")\n",
    "    # print(f\"Current one-hot columns: {current_categorical_one_hot_columns}\")\n",
    "    # print(f\"Current label encode columns: {current_categorical_label_encode_columns}\")   \n",
    "\n",
    "    # Create a new preprocessor with current features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, current_numeric_columns),\n",
    "            (\"cat_onehot\", categorical_onehot_transformer, current_categorical_one_hot_columns),\n",
    "            (\"cat_label\", categorical_label_transformer, current_categorical_label_encode_columns)\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the preprocessor\n",
    "    X_train_processed = preprocessor.fit_transform(new_X_train)\n",
    "    \n",
    "    # Create and fit LightGBM model\n",
    "    model = lgb.LGBMRegressor(**params, verbosity=-1)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    \n",
    "    # Fit the preprocessor\n",
    "    X_train_processed = preprocessor.fit_transform(new_X_train)\n",
    "\n",
    "    # Process validation data and make predictions\n",
    "    X_val = val_df[selected_features]\n",
    "    y_val = val_df[target]\n",
    "    X_val_processed = preprocessor.transform(X_val)\n",
    "    y_pred = model.predict(X_val_processed)\n",
    "    \n",
    "    # Apply inverse transformation\n",
    "    y_pred_inv = inverse_boxcox(y_pred, lambda_value)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_val, y_pred_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmsle = np.sqrt(mean_squared_error(np.log1p(y_val), np.log1p(y_pred_inv)))\n",
    "    \n",
    "    # Store results\n",
    "    all_results.append({\n",
    "        'n_features': len(selected_features),\n",
    "        'features': selected_features.copy(),\n",
    "        'rmse': rmse,\n",
    "        'rmsle': rmsle\n",
    "    })\n",
    "    \n",
    "    # Log the metrics\n",
    "    logging.info(f\"Features: {len(selected_features)} | RMSE: {rmse:.4f} | RMSLE: {rmsle:.4f}\")\n",
    "    \n",
    "    # Track the best performing feature subset\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_rmsle = rmsle\n",
    "        best_features = selected_features.copy()\n",
    "\n",
    "# Sort results by RMSE to find optimal feature count\n",
    "all_results.sort(key=lambda x: x['rmse'])\n",
    "best_result = all_results[0]\n",
    "\n",
    "logging.info(f\"Best Features ({best_result['n_features']}): {best_result['features']} | Best RMSE: {best_result['rmse']:.4f} | Best RMSLE: {best_result['rmsle']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:2829: UserWarning: n_quantiles (1000) is greater than the total number of samples (388). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:2829: UserWarning: n_quantiles (1000) is greater than the total number of samples (774). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:2829: UserWarning: n_quantiles (1000) is greater than the total number of samples (775). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\njoblib.externals.loky.process_executor._RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py\", line 52, in _rfe_single_fit\n    rfe._fit(\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py\", line 335, in _fit\n    importances = _get_feature_importances(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_base.py\", line 234, in _get_feature_importances\n    raise ValueError(\nValueError: when `importance_getter=='auto'`, the underlying estimator TransformedTargetRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/base.py\", line 921, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py\", line 873, in fit\n    scores_features = parallel(\n                      ^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 2007, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n    yield from self._retrieve()\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1754, in _retrieve\n    self._raise_error_fast()\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n    error_job.get_result(self.timeout)\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 745, in get_result\n    return self._return_or_raise()\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 763, in _return_or_raise\n    raise self._result\nValueError: when `importance_getter=='auto'`, the underlying estimator TransformedTargetRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    100\u001b[39m reg1 = Pipeline([\n\u001b[32m    101\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m    102\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mfeature_eliminator\u001b[39m\u001b[33m'\u001b[39m, rfetscv),\n\u001b[32m    103\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, regr)\n\u001b[32m    104\u001b[39m ])\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Cross-validation and RMSE scoring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m mse_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_mean_squared_error\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtcsv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m rmse_scores = np.sqrt(-mse_scores)\n\u001b[32m    110\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAverage RMSE:\u001b[39m\u001b[33m'\u001b[39m, np.mean(rmse_scores))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:431\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    411\u001b[39m results = parallel(\n\u001b[32m    412\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    413\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    429\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\njoblib.externals.loky.process_executor._RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py\", line 52, in _rfe_single_fit\n    rfe._fit(\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py\", line 335, in _fit\n    importances = _get_feature_importances(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_base.py\", line 234, in _get_feature_importances\n    raise ValueError(\nValueError: when `importance_getter=='auto'`, the underlying estimator TransformedTargetRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/base.py\", line 921, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py\", line 873, in fit\n    scores_features = parallel(\n                      ^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 2007, in __call__\n    return output if self.return_generator else list(output)\n                                                ^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1650, in _get_outputs\n    yield from self._retrieve()\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1754, in _retrieve\n    self._raise_error_fast()\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1789, in _raise_error_fast\n    error_job.get_result(self.timeout)\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 745, in get_result\n    return self._return_or_raise()\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lawrence/Documents/PYTHON/saga_tech_test_2025/venv/lib/python3.11/site-packages/joblib/parallel.py\", line 763, in _return_or_raise\n    raise self._result\nValueError: when `importance_getter=='auto'`, the underlying estimator TransformedTargetRegressor should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# Your feature list - corrected to match actual column names\n",
    "features_in_importance_order = ['hour', 'atemp' , 'temp', 'year', 'rush_hour', \n",
    "                                'working_day', 'weathersit', 'day_of_week', 'day', 'hum', 'day_of_year', \n",
    "                                'day_ratio', 'season', 'week_ratio', 'month_cos', 'weekend', \n",
    "                                'windspeed', 'week', 'working_day_or_weekend_ratio', 'holiday', \n",
    "                                'moonphase']\n",
    "\n",
    "# Define features and target\n",
    "target = 'count'\n",
    "\n",
    "numeric_columns = ['temp', 'atemp', 'hum', 'windspeed', 'month_cos', \n",
    "                    'moonphase', 'hour_ratio', \n",
    "                   'day_ratio', 'week_ratio', 'working_day_or_weekend_ratio']\n",
    "\n",
    "categorical_label_encode_columns = ['season', 'year', 'month', 'hour', 'day_of_week', 'weathersit','day', 'week']\n",
    "\n",
    "categorical_one_hot_columns = ['holiday', 'working_day', 'weekend', 'rush_hour']\n",
    "\n",
    "\n",
    "# Combine features into one list\n",
    "features = numeric_columns + categorical_label_encode_columns + categorical_one_hot_columns\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "categorical_onehot_transformer = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Label encoding for other categorical columns\n",
    "categorical_label_transformer = Pipeline([\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Set parameters for LightGBM\n",
    "params = {\n",
    "    'num_leaves': 35,  \n",
    "    'learning_rate': 0.1,  \n",
    "    'n_estimators': 5000, \n",
    "}\n",
    "\n",
    "# Create a preprocessor with all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_columns),\n",
    "        (\"cat_onehot\", categorical_onehot_transformer, categorical_one_hot_columns),\n",
    "        (\"cat_label\", categorical_label_transformer, categorical_label_encode_columns)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "regressor = lgb.LGBMRegressor(**params, verbosity=-1)\n",
    "\n",
    "transformer = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "regr = TransformedTargetRegressor(regressor=regressor,\n",
    "                                  transformer=transformer)\n",
    "\n",
    "tcsv = TimeSeriesSplit(5)\n",
    "\n",
    "rfetscv = RFECV(\n",
    "    estimator=regr,\n",
    "    step=1,\n",
    "    cv=tcsv,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    min_features_to_select=3,\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "reg1 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_eliminator', rfetscv),\n",
    "    ('model', regr)\n",
    "])\n",
    "\n",
    "mse_scores = cross_val_score(reg1, X_train, y_train, scoring='neg_mean_squared_error', cv=tcsv)\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "print('Average RMSE:', np.mean(rmse_scores))\n",
    "print('number of features:', reg1['feature_eliminator'].n_features_)\n",
    "print('Optimal number of features:', rfetscv.n_features_)\n",
    "print('Optimal features:', X_train.columns[rfetscv.support_])\n",
    "X_train = train_df[features].copy()\n",
    "\n",
    "y_train, lambda_value = train_df['count']\n",
    "\n",
    "mse_scores = cross_val_score(reg1, X_train, y_train, scoring='neg_mean_squared_error', cv=tcsv)\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "print('Average RMSE:', np.mean(rmse_scores))\n",
    "print('number of features:', reg1['m'].n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit the pipeline to access the RFECV metrics\n",
    "print(\"Fitting the pipeline to access feature selection metrics...\")\n",
    "reg1.fit(X_train, y_train)\n",
    "\n",
    "# Display feature selection information\n",
    "print('Number of features selected by RFECV:', reg1.named_steps['feature_eliminator'].n_features_)\n",
    "\n",
    "# Get and display the selected features\n",
    "selected_features_mask = reg1.named_steps['feature_eliminator'].support_\n",
    "selected_feature_names = np.array(features)[selected_features_mask].tolist()\n",
    "print('Selected features:', selected_feature_names)\n",
    "\n",
    "# Plot the feature selection scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (neg_mean_squared_error)\")\n",
    "plt.plot(range(1, len(reg1.named_steps['feature_eliminator'].grid_scores_) + 1), \n",
    "         reg1.named_steps['feature_eliminator'].grid_scores_)\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display feature ranking information (1 = selected)\n",
    "feature_ranking = dict(zip(features, reg1.named_steps['feature_eliminator'].ranking_))\n",
    "sorted_ranking = {k: v for k, v in sorted(feature_ranking.items(), key=lambda item: item[1])}\n",
    "print(\"\\nFeature Ranking (1 = selected):\")\n",
    "for feature, rank in sorted_ranking.items():\n",
    "    print(f\"{feature}: {rank}\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "y_pred_train = reg1.predict(X_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"\\nTraining RMSE: {rmse_train:.4f}\")\n",
    "print(f\"Training R²: {r2_train:.4f}\")\n",
    "\n",
    "# Evaluate on validation data\n",
    "X_val_full = val_df[features]\n",
    "y_val_true = val_df[target]\n",
    "y_val_pred = reg1.predict(X_val_full)\n",
    "y_val_pred_inv = inverse_boxcox(y_val_pred, lambda_value)\n",
    "\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val_true, y_val_pred_inv))\n",
    "rmsle_val = np.sqrt(mean_squared_error(np.log1p(y_val_true), np.log1p(y_val_pred_inv)))\n",
    "r2_val = r2_score(y_val_true, y_val_pred_inv)\n",
    "\n",
    "print(f\"\\nValidation RMSE: {rmse_val:.4f}\")\n",
    "print(f\"Validation RMSLE: {rmsle_val:.4f}\")\n",
    "print(f\"Validation R²: {r2_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'atemp', 'hum', 'windspeed', 'year_sin', 'year_cos',\n",
       "       'month_sin', 'month_cos', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos',\n",
       "       'moonphase', 'total_registered_ratio', 'hour_ratio', 'day_ratio',\n",
       "       'week_ratio', 'month_ratio', 'season_ratio',\n",
       "       'working_day_or_weekend_ratio', 'season', 'year', 'month', 'hour',\n",
       "       'day_of_week', 'weathersit', 'day', 'week', 'quarter',\n",
       "       'sigma_3_outlier', 'holiday', 'payday', 'working_day', 'weekend',\n",
       "       'rush_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate the timestamp for training data\n",
    "train_df['timestamp'] = pd.to_datetime({\n",
    "\t'year': train_df['year'], \n",
    "\t'month': train_df['month'], \n",
    "\t'day': train_df['day_of_month']\n",
    "}) + pd.to_timedelta(train_df['hour'], unit='h')\n",
    "\n",
    "val_df['timestamp'] = pd.to_datetime({\n",
    "\t'year': val_df['year'], \n",
    "\t'month': val_df['month'], \n",
    "\t'day': val_df['day_of_month']\n",
    "}) + pd.to_timedelta(val_df['hour'], unit='h')\n",
    "\n",
    "# Residuals and diagnostics\n",
    "residuals = y_val - y_pred_inv\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(residuals, kde=True, color='blue')\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Predicted vs Actual\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_val, y_pred_inv, alpha=0.5, color='green')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.show()\n",
    "\n",
    "# Time series plot with rolling average\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(train_df['timestamp'], train_df[target], label='Actual (Train)', color='blue', alpha=0.5)\n",
    "plt.plot(val_df['timestamp'], y_val, label='Actual (Validation)', color='blue', alpha=0.5)\n",
    "plt.plot(val_df['timestamp'], y_pred_inv, label='Predicted (Validation)', color='orange', alpha=0.5)\n",
    "plt.plot(train_df['timestamp'], train_df[target].rolling(window=24).mean(), label='Actual (Train, Rolling Avg)', color='blue', linewidth=2)\n",
    "plt.plot(val_df['timestamp'], y_val.rolling(window=24).mean(), label='Actual (Validation, Rolling Avg)', color='blue', linewidth=2)\n",
    "plt.plot(val_df['timestamp'], pd.Series(y_pred_inv).rolling(window=24).mean(), label='Predicted (Validation, Rolling Avg)', color='orange', linewidth=2)\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Time Series of Actual vs Predicted Counts with Rolling Average')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
